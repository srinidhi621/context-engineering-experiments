[
  {
    "experiment": "exp1",
    "question_id": "exp1_q001",
    "question": "Example: According to the Llama 3.3-70B Instruct card, what is the maximum context length?",
    "ground_truth": "Context length is 128k tokens.",
    "difficulty": "simple_lookup",
    "required_docs": ["meta-llama/Llama-3.3-70B-Instruct"],
    "evaluation_criteria": "Answer must state 128k tokens.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": ["context window", "128k"],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  }
]
