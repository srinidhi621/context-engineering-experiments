[
  {
    "experiment": "exp1",
    "question_id": "exp1_q001",
    "question": "According to the Llama 3.3-70B Instruct model card, what is the model's context length?",
    "ground_truth": "The Llama 3.3-70B Instruct card specifies a 128k-token context length.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must explicitly state a 128k-token context window.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "context length",
      "128k",
      "Llama 3.3"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q002",
    "question": "What license governs the use of the Llama 3.3-70B Instruct model according to its card?",
    "ground_truth": "Usage is governed by the Llama 3.3 Community License Agreement provided by Meta.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer should mention the 'Llama 3.3 Community License Agreement' by name.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "license",
      "Llama 3.3",
      "community licence"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q003",
    "question": "Does the Llama 3.3-70B Instruct card list supported languages, and if so, which language family does it cover?",
    "ground_truth": "The card lists English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai, indicating coverage of both Indo-European and Indic languages.",
    "difficulty": "synthesis",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer should list at least four of the languages given and mention the multilingual coverage (Indo-European plus Indic).",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "languages",
      "multilingual",
      "Llama 3.3"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q004",
    "question": "According to the Qwen2.5-0.5B model card, what pipeline tag is associated with this model?",
    "ground_truth": "The card tags the pipeline as text-generation.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "Qwen/Qwen2.5-0.5B"
    ],
    "evaluation_criteria": "Answer must state 'text-generation'.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
    "source_model": "Qwen/Qwen2.5-0.5B",
    "keywords": [
      "pipeline_tag",
      "text-generation"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q005",
    "question": "What license governs the Qwen2.5-0.5B model?",
    "ground_truth": "The Qwen2.5-0.5B model is released under the Apache 2.0 license.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "Qwen/Qwen2.5-0.5B"
    ],
    "evaluation_criteria": "Answer must explicitly mention Apache-2.0.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
    "source_model": "Qwen/Qwen2.5-0.5B",
    "keywords": [
      "license",
      "Apache 2.0"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q006",
    "question": "What training data summary does the Llama 3.3 (text-only) row provide?",
    "ground_truth": "The table states that the text-only Llama 3.3 model is trained on a new mix of publicly available online data.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention \"new mix\" and that the data is publicly available online.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "training data",
      "publicly available"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q007",
    "question": "Which input and output modalities are listed for the Llama 3.3 text-only model?",
    "ground_truth": "The table shows Multilingual Text as the input modality and Multilingual Text and code as the output modalities.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must identify both input (multilingual text) and output (multilingual text plus code).",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "modalities",
      "input",
      "output"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q008",
    "question": "What range of parameter sizes does the Qwen2.5 family release according to the 0.5B card?",
    "ground_truth": "The introduction states that Qwen2.5 releases base and instruction-tuned models ranging from 0.5 to 72 billion parameters.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "Qwen/Qwen2.5-0.5B"
    ],
    "evaluation_criteria": "Answer must mention both endpoints: 0.5B and 72B parameters.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
    "source_model": "Qwen/Qwen2.5-0.5B",
    "keywords": [
      "parameters",
      "range",
      "Qwen2.5"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q009",
    "question": "List two capability improvements Qwen2.5 highlights over Qwen2 in its 0.5B card.",
    "ground_truth": "The card states that Qwen2.5 adds significantly more knowledge with improved coding and mathematics experts, and also improves instruction following, long-text generation beyond 8K tokens, structured data understanding, and structured output generation.",
    "difficulty": "synthesis",
    "required_docs": [
      "Qwen/Qwen2.5-0.5B"
    ],
    "evaluation_criteria": "Answer must mention at least two specific improvements cited (e.g., better coding/maths plus improved instruction following or long-text generation).",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
    "source_model": "Qwen/Qwen2.5-0.5B",
    "keywords": [
      "improvements",
      "instruction following",
      "coding",
      "math"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q010",
    "question": "What GQA capability does the Llama 3.3 text-only model indicate in its comparison table?",
    "ground_truth": "The table marks GQA as 'Yes' for the Llama 3.3 text-only row.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must clearly state that GQA is supported (Yes).",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "GQA",
      "table"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q011",
    "question": "What knowledge cutoff is listed for Llama 3.3 in the model table?",
    "ground_truth": "The card lists December 2023 as the knowledge cutoff.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer should say 'December 2023'.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "knowledge cutoff",
      "December 2023"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q012",
    "question": "How many input modalities does the Llama 3.3 text-only model expose?",
    "ground_truth": "The card lists Multilingual Text as the sole input modality.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention only one input modality: multilingual text.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "input modality"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q013",
    "question": "What output modalities does the Llama 3.3 text-only entry support?",
    "ground_truth": "It outputs Multilingual Text and code.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.3-70B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention both text and code outputs.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
    "source_model": "meta-llama/Llama-3.3-70B-Instruct",
    "keywords": [
      "output modalities"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q014",
    "question": "According to the Qwen2.5-0.5B card, what kinds of improvements are driven by specialized expert models?",
    "ground_truth": "The card credits specialized expert models for significantly more knowledge and greatly improved coding and mathematics capabilities.",
    "difficulty": "synthesis",
    "required_docs": [
      "Qwen/Qwen2.5-0.5B"
    ],
    "evaluation_criteria": "Answer must mention both increased knowledge and improvements in coding/mathematics tied to expert models.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
    "source_model": "Qwen/Qwen2.5-0.5B",
    "keywords": [
      "experts",
      "coding",
      "math"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q015",
    "question": "What license governs the use of Llama Guard 3-1B?",
    "ground_truth": "The card states that use is governed by the Llama 3.2 Community License Agreement.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-Guard-3-1B"
    ],
    "evaluation_criteria": "Answer must mention the \"Llama 3.2 Community License Agreement\" by name.",
    "source_url": "https://huggingface.co/meta-llama/Llama-Guard-3-1B",
    "source_model": "meta-llama/Llama-Guard-3-1B",
    "keywords": [
      "license",
      "Llama Guard"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q016",
    "question": "Which languages does the Llama Guard 3-1B card list as supported?",
    "ground_truth": "It lists English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-Guard-3-1B"
    ],
    "evaluation_criteria": "Answer must cite at least four of the listed languages and note the multilingual coverage.",
    "source_url": "https://huggingface.co/meta-llama/Llama-Guard-3-1B",
    "source_model": "meta-llama/Llama-Guard-3-1B",
    "keywords": [
      "languages",
      "multilingual"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q017",
    "question": "What base model does the Llama Guard 3-8B card identify?",
    "ground_truth": "It states that the model is built on meta-llama/Meta-Llama-3.1-8B.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-Guard-3-8B"
    ],
    "evaluation_criteria": "Answer must mention Meta-Llama-3.1-8B as the base.",
    "source_url": "https://huggingface.co/meta-llama/Llama-Guard-3-8B",
    "source_model": "meta-llama/Llama-Guard-3-8B",
    "keywords": [
      "base model",
      "Llama Guard"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q018",
    "question": "Which license applies to Llama Guard 3-8B?",
    "ground_truth": "The card references the Llama 3.1 Community License Agreement.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-Guard-3-8B"
    ],
    "evaluation_criteria": "Answer must cite the Llama 3.1 Community License Agreement.",
    "source_url": "https://huggingface.co/meta-llama/Llama-Guard-3-8B",
    "source_model": "meta-llama/Llama-Guard-3-8B",
    "keywords": [
      "license",
      "Llama Guard"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q019",
    "question": "According to the Llama 3.2 text-only model table, what context length is supported?",
    "ground_truth": "The table lists a 128k-token context length for Llama 3.2 text-only models.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.2-3B"
    ],
    "evaluation_criteria": "Answer must state 128k tokens.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.2-3B",
    "source_model": "meta-llama/Llama-3.2-3B",
    "keywords": [
      "context length",
      "128k"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q020",
    "question": "What input and output modalities are listed for the Llama 3.2 text-only row?",
    "ground_truth": "Inputs are Multilingual Text, while outputs are Multilingual Text and code.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.2-3B"
    ],
    "evaluation_criteria": "Answer must mention the Multilingual Text input and Multilingual Text plus code output.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.2-3B",
    "source_model": "meta-llama/Llama-3.2-3B",
    "keywords": [
      "modalities"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q021",
    "question": "What use cases are the Llama 3.2 instruction-tuned text-only models optimized for?",
    "ground_truth": "They are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.2-3B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention multilingual dialogue plus agentic retrieval and summarization.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "source_model": "meta-llama/Llama-3.2-3B-Instruct",
    "keywords": [
      "use cases",
      "agentic retrieval",
      "summarization"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q022",
    "question": "What training techniques does the Llama 3.2 card mention for aligning the instruction-tuned models?",
    "ground_truth": "It states the tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).",
    "difficulty": "simple_lookup",
    "required_docs": [
      "meta-llama/Llama-3.2-3B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention both SFT and RLHF.",
    "source_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "source_model": "meta-llama/Llama-3.2-3B-Instruct",
    "keywords": [
      "SFT",
      "RLHF"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q023",
    "question": "Which datasets does the Phi-3.5-mini-instruct summary say it is built upon?",
    "ground_truth": "The summary states it is built upon the datasets used for Phi-3: synthetic data and filtered publicly available websites.",
    "difficulty": "simple_lookup",
    "required_docs": [
      "microsoft/Phi-3.5-mini-instruct"
    ],
    "evaluation_criteria": "Answer must mention both synthetic data and filtered publicly available websites.",
    "source_url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "source_model": "microsoft/Phi-3.5-mini-instruct",
    "keywords": [
      "Phi-3.5",
      "synthetic data",
      "filtered web"
    ],
    "answer_format": "short_fact",
    "metadata": {
      "category": "model_card",
      "expected_citations": 1
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q024",
    "question": "Compare the Gemma 2-9B base model and Gemma 2-2B instruction-tuned variant: what common design goals do they share according to their cards?",
    "ground_truth": "Both cards describe Gemma models as lightweight text-to-text decoder-only LLMs built from Gemini research, intended for text generation tasks such as question answering, summarization, and reasoning, and suitable for deployment in resource-limited environments like laptops or personal cloud setups.",
    "difficulty": "synthesis",
    "required_docs": [
      "google/gemma-2-9b",
      "google/gemma-2-2b-it"
    ],
    "evaluation_criteria": "Answer must mention at least one shared design goal (text-to-text decoder-only, lightweight) and one shared use case (e.g., QA, summarization, reasoning) present in both cards, plus acknowledge deployment in resource-limited settings.",
    "source_url": "https://huggingface.co/google/gemma-2-9b",
    "source_model": "google/gemma-2-9b",
    "keywords": [
      "Gemma",
      "comparison"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q025",
    "question": "According to the OpenAI Whisper large-v3 and Whisper large-v3-turbo cards, which variant requires acknowledging a license/gating step, and what are the stated licensing differences?",
    "ground_truth": "Whisper large-v3-turbo requires users to acknowledge the OpenAI license via the gated workflow, and it is released under the MIT license; Whisper large-v3 is provided under Apache-2.0 without the extra gating step.",
    "difficulty": "contradiction",
    "required_docs": [
      "openai/whisper-large-v3",
      "openai/whisper-large-v3-turbo"
    ],
    "evaluation_criteria": "Answer must identify that the turbo model adds a gating/license acknowledgement step and that the base model uses Apache-2.0 while turbo uses MIT.",
    "source_url": "https://huggingface.co/openai/whisper-large-v3",
    "source_model": "openai/whisper-large-v3",
    "keywords": [
      "Whisper",
      "turbo",
      "license"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q026",
    "question": "Contrast the stated use cases or strengths of Phi-3.5-mini-instruct versus Phi-3.5-MoE-instruct. What key differences does Microsoft highlight between the two cards?",
    "ground_truth": "Both cards mention 128K context, synthetic plus filtered public data, and instruction tuning, but the MoE card specifically emphasizes deployment in memory/compute constrained environments with latency bounds and highlights strong reasoning (code, math, logic), whereas the mini card focuses on lightweight general-purpose text generation.",
    "difficulty": "synthesis",
    "required_docs": [
      "microsoft/Phi-3.5-mini-instruct",
      "microsoft/Phi-3.5-MoE-instruct"
    ],
    "evaluation_criteria": "Answer must cite at least one common trait (e.g., 128K context, synthetic + filtered data) and at least one differentiator (MoE\u2019s emphasis on memory/compute constraints or reasoning vs. mini\u2019s general lightweight focus).",
    "source_url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "source_model": "microsoft/Phi-3.5-mini-instruct",
    "keywords": [
      "Phi-3.5",
      "comparison"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q028",
    "question": "According to the Phi-3.5-vision-instruct card, what additional capabilities does it highlight beyond the Phi-3.5 mini and MoE text-only models?",
    "ground_truth": "The vision card explicitly highlights multimodal capabilities including general image understanding, OCR, chart/table understanding, multi-image comparison, and multi-image or video clip summarization, whereas the mini/MoE cards focus on text-only reasoning and lightweight deployment.",
    "difficulty": "synthesis",
    "required_docs": [
      "microsoft/Phi-3.5-vision-instruct",
      "microsoft/Phi-3.5-mini-instruct",
      "microsoft/Phi-3.5-MoE-instruct"
    ],
    "evaluation_criteria": "Answer must mention at least two vision-specific tasks (e.g., OCR, chart understanding, multi-image comparison) that differentiate the vision card from the text-only cards.",
    "source_url": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "source_model": "microsoft/Phi-3.5-vision-instruct",
    "keywords": [
      "Phi-3.5",
      "vision"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 3
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q027",
    "question": "Contrast the stated use cases or strengths of Phi-3.5-mini-instruct versus Phi-3.5-MoE-instruct. What key differences does Microsoft highlight between the two cards?",
    "ground_truth": "Both cards share 128K context and synthetic plus filtered data, but the MoE card specifically emphasizes deployment in memory/compute constrained and latency-bound environments with strong reasoning (code, math, logic), whereas the mini card focuses on lightweight general-purpose text generation.",
    "difficulty": "synthesis",
    "required_docs": [
      "microsoft/Phi-3.5-mini-instruct",
      "microsoft/Phi-3.5-MoE-instruct"
    ],
    "evaluation_criteria": "Answer must mention at least one shared trait (128K context or data sources) and at least one differentiator (MoE's emphasis on memory/compute constraints or reasoning vs. mini's general text generation focus).",
    "source_url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "source_model": "microsoft/Phi-3.5-mini-instruct",
    "keywords": [
      "Phi-3.5",
      "comparison"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q029",
    "question": "According to the Phi-3.5-vision-instruct card, what additional capabilities does it highlight beyond the Phi-3.5 mini and MoE text-only models?",
    "ground_truth": "The vision card explicitly highlights multimodal capabilities including general image understanding, OCR, chart/table understanding, multi-image comparison, and multi-image or video clip summarization, whereas the mini/MoE cards focus on text-only reasoning and lightweight deployment.",
    "difficulty": "synthesis",
    "required_docs": [
      "microsoft/Phi-3.5-vision-instruct",
      "microsoft/Phi-3.5-mini-instruct",
      "microsoft/Phi-3.5-MoE-instruct"
    ],
    "evaluation_criteria": "Answer must mention at least two vision-specific tasks (e.g., OCR, chart understanding, multi-image comparison) that differentiate the vision card from the text-only cards.",
    "source_url": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "source_model": "microsoft/Phi-3.5-vision-instruct",
    "keywords": [
      "Phi-3.5",
      "vision"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 3
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q030",
    "question": "Which Gemma 2 variant explicitly mentions a conversational tag and base model field, and what does this imply about its intended use compared to the base Gemma 2-9B card?",
    "ground_truth": "The Gemma 2-9B-it (instruction-tuned) card includes the 'conversational' tag and a base_model entry referencing google/gemma-2-9b, indicating it is tuned for conversational/instruction use compared to the generic base Gemma 2-9B card.",
    "difficulty": "synthesis",
    "required_docs": [
      "google/gemma-2-9b",
      "google/gemma-2-9b-it"
    ],
    "evaluation_criteria": "Answer must identify that the instruction-tuned card carries the conversational tag and base_model pointer, and explain that this signals conversational instruction tuning compared to the base card.",
    "source_url": "https://huggingface.co/google/gemma-2-9b-it",
    "source_model": "google/gemma-2-9b-it",
    "keywords": [
      "Gemma",
      "instruction tuning"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q031",
    "question": "Compare Mistral-Small-Instruct-2409 and Pixtral-12B-2409: what licensing and modality differences do their cards highlight?",
    "ground_truth": "Mistral-Small-Instruct-2409 uses the Mistral Research License (MRL) and targets multilingual text generation, while Pixtral-12B-2409 is Apache-2.0 licensed, multimodal (text + images) with a 12B decoder and 400M vision encoder, emphasizing image-related benchmarks.",
    "difficulty": "synthesis",
    "required_docs": [
      "mistralai/Mistral-Small-Instruct-2409",
      "mistralai/Pixtral-12B-2409"
    ],
    "evaluation_criteria": "Answer must mention the different licenses (MRL vs Apache-2.0) and note Pixtral's multimodal design in contrast to the text-focused Mistral Small Instruct card.",
    "source_url": "https://huggingface.co/mistralai/Pixtral-12B-2409",
    "source_model": "mistralai/Pixtral-12B-2409",
    "keywords": [
      "Mistral",
      "Pixtral",
      "license",
      "multimodal"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q032",
    "question": "What additions does the Qwen2.5-7B-Instruct card mention compared to the base Qwen2.5-7B entry?",
    "ground_truth": "Both share the same architecture and improvements, but the Instruct card explicitly tags the model for chat use, references the Chat Qwen link, and notes that it is an instruction-tuned variant built on the base model, targeting improved instruction following and chatbot condition-setting.",
    "difficulty": "synthesis",
    "required_docs": [
      "Qwen/Qwen2.5-7B",
      "Qwen/Qwen2.5-7B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention at least one instruct-specific element (e.g., chat tag, instruction tuning, Qwen Chat link) absent from the base card.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
    "source_model": "Qwen/Qwen2.5-7B-Instruct",
    "keywords": [
      "Qwen",
      "instruction"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  },
  {
    "experiment": "exp1",
    "question_id": "exp1_q033",
    "question": "Qwen2.5-7B vs Qwen2.5-7B-Instruct: what explicit chat-optimized additions does the instruct card mention?",
    "ground_truth": "The instruct card carries the chat tag, links to Qwen Chat, and states it is an instruction-tuned variant built on the base model to improve instruction following and system prompt resilience, which is not emphasized in the base 7B card.",
    "difficulty": "synthesis",
    "required_docs": [
      "Qwen/Qwen2.5-7B",
      "Qwen/Qwen2.5-7B-Instruct"
    ],
    "evaluation_criteria": "Answer must mention at least one instruct-specific detail (chat tag, Qwen Chat link, instruction tuning emphasis) absent from the base card.",
    "source_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
    "source_model": "Qwen/Qwen2.5-7B-Instruct",
    "keywords": [
      "Qwen",
      "chat"
    ],
    "answer_format": "short_paragraph",
    "metadata": {
      "category": "model_card",
      "expected_citations": 2
    }
  }
]